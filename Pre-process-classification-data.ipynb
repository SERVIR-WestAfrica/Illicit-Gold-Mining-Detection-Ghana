{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import image_utils as iu\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image, ImageEnhance\n",
    "from PIL import ImageFilter\n",
    "from shutil import copy2\n",
    "import matplotlib.pyplot as plt\n",
    "import geotiff_utils as gu\n",
    "import uuid\n",
    "import shutil\n",
    "import numpy_utils as nu\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 3520956600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'E:\\\\Staff\\\\Asare\\\\Ssm\\\\data'\n",
    "segmentation_path = os.path.join(data_path, 'segmentation')\n",
    "original_path = os.path.join(segmentation_path, 'original')\n",
    "real_data_path = os.path.join(original_path, 'real')\n",
    "mask_data_path = os.path.join(original_path, 'mask')\n",
    "# divided images\n",
    "divided_data_path = os.path.join(segmentation_path, 'divided')\n",
    "real_divided_data_path = os.path.join(divided_data_path, 'real')\n",
    "mask_divided_data_path = os.path.join(divided_data_path, 'mask')\n",
    "#\n",
    "final_data_path = os.path.join(segmentation_path, 'final')\n",
    "real_final_data_path = os.path.join(final_data_path, 'real')\n",
    "mask_final_data_path = os.path.join(final_data_path, 'mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create base dir's\n",
    "iu.create_dir_if_not_exists(data_path)\n",
    "iu.create_dir_if_not_exists(segmentation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the path of an image and a mask pair\n",
    "class DataLabelPair:\n",
    "    def __init__(self, data_real_path, label_path):\n",
    "        self.data_real_path = data_real_path\n",
    "        self.label_path = label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the class mappings\n",
    "class_encoding = {0: 'No Data',\n",
    "                  1: 'Active-Mines',\n",
    "                  2: 'Abandoned-Mines',\n",
    "                  3: 'Polluted-Rivers'}\n",
    "\n",
    "r_class_encoding = {v: k for k, v in class_encoding.items()}\n",
    "# print(reversed_dict)\n",
    "new_color_encoding = {3: [255, 255, 0], \n",
    "                      2: [180, 96, 0], \n",
    "                      1: [251, 72, 196],  \n",
    "                      0: [0, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_legend(np_image, color_encoding):\n",
    "    flat_gh_im = np_image.reshape(-1, 1)\n",
    "    #\n",
    "    new_gh_im = [None] * flat_gh_im.shape[0]\n",
    "    for x in range(flat_gh_im.shape[0]):\n",
    "        new_gh_im[x] = color_encoding.get(flat_gh_im[x][0], [0, 0, 0])\n",
    "    #\n",
    "    new_gh_im = np.array(new_gh_im).reshape(\n",
    "        np_image.shape[0], np_image.shape[1], 3)\n",
    "    enc_im = Image.fromarray(np.array(new_gh_im, dtype=np.uint8))\n",
    "    return enc_im\n",
    "\n",
    "# Splits image into specified rows and columns\n",
    "def split_geoTiff_image(geoTiff, max_grid_size, strides):\n",
    "    parts = []\n",
    "    width, height = geoTiff.RasterXSize, geoTiff.RasterYSize\n",
    "    left = 0\n",
    "    top = 0\n",
    "    stride_width, stride_height = strides\n",
    "    max_grid_width, max_grid_height = max_grid_size\n",
    "    total_grids = np.ceil(height / stride_width) * np.ceil(width / stride_height)\n",
    "    for r in range(0, height, stride_height):\n",
    "        for c in range(0, width, stride_width):\n",
    "            left, top = c, r\n",
    "            right, bottom = min(\n",
    "                    c + max_grid_width, width), min(r + max_grid_height,height)\n",
    "            grid = gu.crop_geoTiff(\n",
    "                    geoTiff, left, top, right, bottom, 'uint16')\n",
    "            # part = gu.crop_geoTiff(geoTiff, left, top, right, bottom)\n",
    "            parts.append(grid)\n",
    "    return parts\n",
    "\n",
    "def split_image(image, max_grid_size, strides):\n",
    "    parts = []\n",
    "    width, height = image.size\n",
    "    left = 0\n",
    "    top = 0\n",
    "    stride_width, stride_height = strides\n",
    "    max_grid_width, max_grid_height = max_grid_size\n",
    "    for r in range(0, height, stride_height):\n",
    "        for c in range(0, width, stride_width):\n",
    "            left, top = c, r\n",
    "            right, bottom = min(\n",
    "                    c + max_grid_width, width), min(r + max_grid_height,height)\n",
    "            grid = image.crop((left, top, right, bottom))\n",
    "            # part = gu.crop_geoTiff(geoTiff, left, top, right, bottom)\n",
    "            parts.append(grid)\n",
    "    return parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets all mask files in the mask folder\n",
    "original_mask_images_path = iu.get_all_files(mask_data_path, '*.png')\n",
    "print(len(original_mask_images_path), 'Labeled Files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_original = []\n",
    "for path in original_mask_images_path:\n",
    "    image = DataLabelPair(os.path.join(real_data_path, path.replace('.png', '.tif')),\n",
    "                          os.path.join(mask_data_path, path))\n",
    "    images_original.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_grid_size = (512,512)\n",
    "strides = (128, 128)\n",
    "# images are divided into smaller images.\n",
    "# This reduces the dimension of the images and also increases the training data.\n",
    "iu.create_dir_if_not_exists(mask_divided_data_path)\n",
    "iu.create_dir_if_not_exists(real_divided_data_path)\n",
    "iu.create_dir_if_not_exists(mask_divided_data_path)\n",
    "i = 0\n",
    "for image_original in images_original:\n",
    "    real_image = gdal.Open(image_original.data_real_path)\n",
    "    part_count = col_count * row_count\n",
    "    np_real_image = gu.read_geoTiff_bands(real_image)\n",
    "    mask_image = iu.read_image(image_original.label_path, 'L')\n",
    "    real_image_parts = split_geoTiff_image(real_image, max_grid_size, strides)\n",
    "    mask_image_parts = split_image(mask_image, max_grid_size, strides)\n",
    "    for x in range(len(real_image_parts)):\n",
    "        part_filename = str(uuid.uuid4())\n",
    "        real_image_part = real_image_parts[x]\n",
    "        mask_image_part = mask_image_parts[x]\n",
    "        # Save the arrays to a .npz file\n",
    "        nu.save_numpy_file(real_image_part, os.path.join(\n",
    "            real_divided_data_path, part_filename + '.npz'))\n",
    "        mask_image_part.save(os.path.join(\n",
    "            mask_divided_data_path, part_filename + '.png'))\n",
    "    i += 1\n",
    "    iu.print_progress(i, len(images_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images that do not contain any information is deleted from storage.\n",
    "divided_images_path = iu.get_all_files(mask_divided_data_path)\n",
    "print(len(divided_images_path), 'Divided files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_divided = []\n",
    "for path in divided_images_path:\n",
    "    image = DataLabelPair(os.path.join(real_divided_data_path, path.replace('.png', '.npz')),\n",
    "                          os.path.join(mask_divided_data_path, path))\n",
    "    images_divided.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlay_mask(original_image, mask_image):\n",
    "    # Open the image and mask\n",
    "    image = original_image.convert('RGBA')\n",
    "    mask = mask_image.convert('RGBA')\n",
    "\n",
    "    # Make pixel value [0, 0, 0] transparent in the mask\n",
    "    mask_data = mask.getdata()\n",
    "    new_mask_data = []\n",
    "    for item in mask_data:\n",
    "        if item[:3] == (0, 0, 0):\n",
    "            # Set transparency for [0, 0, 0]\n",
    "            new_mask_data.append((0, 0, 0, 0))\n",
    "        else:\n",
    "            new_mask_data.append(item)\n",
    "    mask.putdata(new_mask_data)\n",
    "\n",
    "    # Overlay the mask on the image\n",
    "    overlaid = Image.alpha_composite(image, mask)\n",
    "\n",
    "    # Save the overlaid image\n",
    "    return overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20  12\n",
    "import random\n",
    "indx = random.randint(0, len(divided_images_path))\n",
    "np_gt = nu.load_numpy_file(images_divided[indx].data_real_path) \n",
    "real_im = gu.display_np_geoTiff(np_gt, (2, 1, 0))\n",
    "#\n",
    "np_gh_img = np.asarray(iu.read_image(\n",
    "    images_divided[indx].label_path))\n",
    "mask = display_legend(np_gh_img, new_color_encoding)\n",
    "display_images({'Satellite Image': real_im, 'Mask': mask,\n",
    "                'Overlay': overlay_mask(real_im, mask)}, (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad_array(input_array, new_shape):\n",
    "    \"\"\"\n",
    "    Zero-pad the input_array to the specified new_shape.\n",
    "    Args:\n",
    "        input_array (numpy.ndarray): Input array of shape (height, width, x).\n",
    "        new_shape (tuple): Desired new shape (new_height, new_width, x).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Zero-padded array of shape (new_height, new_width, x).\n",
    "    \"\"\"\n",
    "    if input_array.shape[0] >= new_shape[0] and input_array.shape[1] >= new_shape[1]:\n",
    "        return input_array\n",
    "    # Calculate the amount of padding needed for each dimension\n",
    "    pad_height = new_shape[0] - input_array.shape[0]\n",
    "    pad_width = new_shape[1] - input_array.shape[1]\n",
    "    # Create a tuple of padding values for each dimension\n",
    "    pad_values = [(0, pad_height), (0, pad_width)] + [(0, 0)] * (input_array.ndim - 2)\n",
    "    # Use numpy.pad to pad the array with zeros\n",
    "    zero_padded_array = np.pad(input_array, pad_values, mode='constant', constant_values=0)\n",
    "    return zero_padded_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Augments images by rotation.\n",
    "def aug_image(image, new_size=None):\n",
    "    width, height = image.size\n",
    "    if new_size == None:\n",
    "        new_size = (width, height)\n",
    "    images_augmented = []\n",
    "    np_image = np.asarray(image)\n",
    "    np_image = zero_pad_array(np_image, new_size)\n",
    "    image = Image.fromarray(np_image)\n",
    "    # image = image.resize(new_size, resample=Image.BOX)\n",
    "    new_im = image\n",
    "    images_augmented.append(new_im)\n",
    "    images_augmented.append(new_im.rotate(360 - 90))\n",
    "    images_augmented.append(new_im.rotate(360 - 180))\n",
    "    images_augmented.append(new_im.rotate(360 - 270))\n",
    "    new_im = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    images_augmented.append(new_im)\n",
    "    images_augmented.append(new_im.rotate(360 - 90))\n",
    "    images_augmented.append(new_im.rotate(360 - 180))\n",
    "    images_augmented.append(new_im.rotate(360 - 270))\n",
    "    return images_augmented\n",
    "\n",
    "\n",
    "def aug_np_image(np_image, new_size=None):\n",
    "    height, width, channels = np_image.shape[0], np_image.shape[1], np_image.shape[2]\n",
    "    if new_size == None:\n",
    "        new_size = (height, width)\n",
    "    np_images_aug = []\n",
    "    # np_image = nu.resize_np_image(np_image, new_size)\n",
    "    np_image = zero_pad_array(np_image, new_size)\n",
    "    new_np_im = np_image\n",
    "    np_images_aug.append(new_np_im)\n",
    "    np_images_aug.append(nu.rotate_np_image(new_np_im, 90))\n",
    "    np_images_aug.append(nu.rotate_np_image(new_np_im, 180))\n",
    "    np_images_aug.append(nu.rotate_np_image(new_np_im, 270))\n",
    "    new_np_im = nu.flip_np_image_left_right(np_image)\n",
    "    np_images_aug.append(new_np_im)\n",
    "    np_images_aug.append(nu.rotate_np_image(new_np_im, 90))\n",
    "    np_images_aug.append(nu.rotate_np_image(new_np_im, 180))\n",
    "    np_images_aug.append(nu.rotate_np_image(new_np_im, 270))\n",
    "    return np_images_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images are augmented and saved on disk.\n",
    "iu.create_dir_if_not_exists(final_data_path)\n",
    "iu.create_dir_if_not_exists(real_final_data_path)\n",
    "iu.create_dir_if_not_exists(mask_final_data_path)\n",
    "i = 0\n",
    "for divided_image in images_divided:\n",
    "    mask_image = iu.read_image(divided_image.label_path, 'L')\n",
    "    np_mask_image = np.asarray(mask_image)\n",
    "    real_image = nu.load_numpy_file(\n",
    "        divided_image.data_real_path.replace('.png', '.npz'))\n",
    "    #The max reflectance value in the geotiff is clipped to 6000.\n",
    "    real_image = np.clip(real_image, None, 6000)\n",
    "    im_size = (512, 512)\n",
    "    forest_p = get_class_percentages(np_mask_image).get(0, 0)\n",
    "    real_aug_images = aug_np_image(real_image, im_size)\n",
    "    mask_aug_images = aug_image(mask_image, im_size)\n",
    "    for x in range(len(real_aug_images)):\n",
    "        part_filename = str(uuid.uuid4())\n",
    "        real_image_part = real_aug_images[x]\n",
    "        mask_image_part = mask_aug_images[x]\n",
    "        np_mask_image_part = np.asarray(mask_image_part)\n",
    "        # np_mask_image_part = np.where(\n",
    "        #     np_mask_image_part == 0, np_mask_image_part, 1)\n",
    "        np_mask_image_part = np_mask_image_part.reshape(\n",
    "            (np_mask_image_part.shape[0], np_mask_image_part.shape[1]))\n",
    "        #\n",
    "        nu.save_numpy_file(real_image_part, os.path.join(\n",
    "            real_final_data_path, part_filename + '.npz'))\n",
    "\n",
    "        mask_image_part = Image.fromarray(np_mask_image_part)\n",
    "        mask_image_part.save(os.path.join(\n",
    "            mask_final_data_path, part_filename + '.png'))\n",
    "    # os.remove(divided_image.data_real_path.replace('.png', '.npz'))\n",
    "    # os.remove(divided_image.label_path)\n",
    "    i += 1\n",
    "    iu.print_progress(i, len(images_divided))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2306"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_images_path = iu.get_all_files(real_final_data_path, '*.npz')\n",
    "len(final_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_final = []\n",
    "for path in final_images_path:\n",
    "    image = DataLabelPair(os.path.join(real_final_data_path, path),\n",
    "                          os.path.join(mask_final_data_path, path.replace('.npz', '.png')))\n",
    "    images_final.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20  12\n",
    "import random\n",
    "indx = random.randint(0, len(final_images_path))\n",
    "np_gt = nu.load_numpy_file(images_final[indx].data_real_path) \n",
    "real_im = gu.display_np_geoTiff(np_gt, (2, 1, 0))\n",
    "#\n",
    "np_gh_img = np.asarray(iu.read_image(\n",
    "    images_final[indx].label_path))\n",
    "mask = display_legend(np_gh_img, new_color_encoding)\n",
    "display_images({'Satellite Image': real_im, 'Mask': mask,\n",
    "                'Overlay': overlay_mask(real_im, mask)}, (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits dataset into training, validation and test sets.\n",
    "def train_val_test_split(val_per, test_per, input_data, labels=None):\n",
    "    if labels is not None and len(input_data) != len(labels):\n",
    "        raise Exception(\"input data and label length mismatch\")\n",
    "    data_len = len(input_data)\n",
    "    val_len = int(data_len * (val_per / 100))\n",
    "    test_len = int(data_len * (test_per / 100))\n",
    "    x_val = input_data[0: val_len]\n",
    "    x_test = input_data[val_len: val_len + test_len]\n",
    "    x_train = input_data[val_len + test_len: data_len]\n",
    "    if labels is not None:\n",
    "        y_val = labels[0: val_len]\n",
    "        y_test = labels[val_len: val_len + test_len]\n",
    "        y_train = labels[val_len + test_len: data_len]\n",
    "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "    else:\n",
    "        return x_train, x_val, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, test_images = train_val_test_split(\n",
    "    20, 0, images_final)\n",
    "print('Train length:', len(train_images))\n",
    "print('Val length:', len(val_images))\n",
    "print('Test length', len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create directories for all training data.\n",
    "training_path = os.path.join(segmentation_path, 'training')\n",
    "iu.create_dir_if_not_exists(training_path)\n",
    "#train\n",
    "train_path = os.path.join(training_path, 'train')\n",
    "iu.create_dir_if_not_exists(train_path)\n",
    "train_real_path = os.path.join(train_path, 'real')\n",
    "iu.create_dir_if_not_exists(train_real_path)\n",
    "train_mask_path = os.path.join(train_path, 'mask')\n",
    "iu.create_dir_if_not_exists(train_mask_path)\n",
    "#val\n",
    "val_path = os.path.join(training_path, 'val')\n",
    "iu.create_dir_if_not_exists(val_path)\n",
    "val_real_path = os.path.join(val_path, 'real')\n",
    "iu.create_dir_if_not_exists(val_real_path)\n",
    "val_mask_path = os.path.join(val_path, 'mask')\n",
    "iu.create_dir_if_not_exists(val_mask_path)\n",
    "#test\n",
    "test_path = os.path.join(training_path, 'test')\n",
    "iu.create_dir_if_not_exists(test_path)\n",
    "test_real_path = os.path.join(test_path, 'real')\n",
    "iu.create_dir_if_not_exists(test_real_path)\n",
    "test_mask_path = os.path.join(test_path, 'mask')\n",
    "iu.create_dir_if_not_exists(test_mask_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move training images to training folder\n",
    "i = 0\n",
    "for image in train_images:\n",
    "    shutil.move(image.data_real_path, os.path.join(\n",
    "        train_real_path, os.path.basename(image.data_real_path)))\n",
    "    shutil.move(image.label_path, os.path.join(\n",
    "        train_mask_path, os.path.basename(image.label_path)))\n",
    "    i += 1\n",
    "    iu.print_progress(i, len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move validation images to validation folder\n",
    "i = 0\n",
    "for image in val_images:\n",
    "    shutil.move(image.data_real_path, os.path.join(\n",
    "        val_real_path, os.path.basename(image.data_real_path)))\n",
    "    shutil.move(image.label_path, os.path.join(\n",
    "        val_mask_path, os.path.basename(image.label_path)))\n",
    "    i += 1\n",
    "    iu.print_progress(i, len(val_images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('ml-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
